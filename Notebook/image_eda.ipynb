{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d336e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe05d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IMAGE DATASET ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Total images found: 712\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../Data/0325updated.task1train(626p)-20251119T175414Z-1-001/0325updated.task1train(626p)'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"IMAGE DATASET ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find all image files\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.gif']\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(glob.glob(os.path.join(data_dir, ext)))\n",
    "\n",
    "print(f\"\\nTotal images found: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1135f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing images...\n",
      "\n",
      "============================================================\n",
      "IMAGE STATISTICS\n",
      "============================================================\n",
      "\n",
      "üìê Dimensions:\n",
      "   Width  - Min:  436px | Max: 4961px | Avg: 1269.9px\n",
      "   Height - Min:  605px | Max: 7016px | Avg: 2283.6px\n",
      "\n",
      "üìä Aspect Ratios:\n",
      "   Min: 0.263 | Max: 0.971 | Avg: 0.511\n",
      "\n",
      "‚ö† Images have DIFFERENT dimensions (500 unique sizes)\n",
      "   Most common sizes:\n",
      "     4961x7016: 74 images (10.4%)\n",
      "     1080x1527: 17 images (2.4%)\n",
      "     1080x1528: 13 images (1.8%)\n",
      "     793x1373: 5 images (0.7%)\n",
      "     619x1475: 4 images (0.6%)\n",
      "\n",
      "üé® Color Modes:\n",
      "   RGB: 708 images (99.4%)\n",
      "   L: 4 images (0.6%)\n",
      "\n",
      "üì¶ File Sizes:\n",
      "   Min: 57.8 KB | Max: 3540.2 KB | Avg: 535.5 KB\n",
      "\n",
      "‚úì All images loaded successfully!\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "üîß Required preprocessing steps:\n",
      "\n",
      "1. RESIZE IMAGES ‚ö†Ô∏è\n",
      "   Issue: 500 different image sizes\n",
      "   Action: Resize all images to consistent dimensions\n",
      "   Suggested size: 4961x7016 (most common)\n",
      "\n",
      "2. NORMALIZATION\n",
      "   Action: Normalize pixel values to [0, 1] or [-1, 1]\n",
      "   Current: Pixel values likely in [0, 255]\n",
      "\n",
      "3. COLOR MODE CONVERSION (Optional)\n",
      "   Current modes: RGB, L\n",
      "   Consider: Converting to grayscale if color not needed\n",
      "   Benefits: Reduces model complexity, faster training\n",
      "\n",
      "4. DATA AUGMENTATION (Recommended)\n",
      "   Techniques to consider:\n",
      "   - Random rotation (¬±5-10¬∞)\n",
      "   - Random brightness/contrast adjustment\n",
      "   - Random scaling (90-110%)\n",
      "   - Elastic distortions (for text/OCR tasks)\n",
      "   Benefits: Improves model generalization\n",
      "\n",
      "5. VERIFY IMAGE-TEXT PAIRS\n",
      "   Action: Ensure each image has corresponding text file\n",
      "   Images: 712\n",
      "   Text files: 835\n",
      "   ‚ö†Ô∏è MISMATCH: 123 files difference\n"
     ]
    }
   ],
   "source": [
    "if len(image_files) == 0:\n",
    "    print(\"No images found! Please check the directory path.\")\n",
    "else:\n",
    "    # Analyze images\n",
    "    print(\"\\nAnalyzing images...\")\n",
    "    \n",
    "    widths = []\n",
    "    heights = []\n",
    "    aspect_ratios = []\n",
    "    modes = []\n",
    "    file_sizes = []\n",
    "    channels = []\n",
    "    \n",
    "    corrupted_files = []\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            # Get file size\n",
    "            file_size = os.path.getsize(img_path) / 1024  # KB\n",
    "            file_sizes.append(file_size)\n",
    "            \n",
    "            # Open and analyze image\n",
    "            img = Image.open(img_path)\n",
    "            widths.append(img.width)\n",
    "            heights.append(img.height)\n",
    "            aspect_ratios.append(img.width / img.height)\n",
    "            modes.append(img.mode)\n",
    "            \n",
    "            # Count channels\n",
    "            if img.mode == 'RGB':\n",
    "                channels.append(3)\n",
    "            elif img.mode == 'RGBA':\n",
    "                channels.append(4)\n",
    "            elif img.mode == 'L':\n",
    "                channels.append(1)\n",
    "            else:\n",
    "                channels.append(len(img.getbands()))\n",
    "                \n",
    "        except Exception as e:\n",
    "            corrupted_files.append((os.path.basename(img_path), str(e)))\n",
    "    \n",
    "    # Statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMAGE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìê Dimensions:\")\n",
    "    print(f\"   Width  - Min: {min(widths):4d}px | Max: {max(widths):4d}px | Avg: {np.mean(widths):.1f}px\")\n",
    "    print(f\"   Height - Min: {min(heights):4d}px | Max: {max(heights):4d}px | Avg: {np.mean(heights):.1f}px\")\n",
    "    \n",
    "    print(f\"\\nüìä Aspect Ratios:\")\n",
    "    print(f\"   Min: {min(aspect_ratios):.3f} | Max: {max(aspect_ratios):.3f} | Avg: {np.mean(aspect_ratios):.3f}\")\n",
    "    \n",
    "    # Check if dimensions are consistent\n",
    "    unique_dims = set(zip(widths, heights))\n",
    "    if len(unique_dims) == 1:\n",
    "        print(f\"\\n‚úì All images have SAME dimensions: {widths[0]}x{heights[0]}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö† Images have DIFFERENT dimensions ({len(unique_dims)} unique sizes)\")\n",
    "        print(f\"   Most common sizes:\")\n",
    "        dim_counter = Counter(zip(widths, heights))\n",
    "        for (w, h), count in dim_counter.most_common(5):\n",
    "            print(f\"     {w}x{h}: {count} images ({count/len(image_files)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüé® Color Modes:\")\n",
    "    mode_counter = Counter(modes)\n",
    "    for mode, count in mode_counter.most_common():\n",
    "        print(f\"   {mode}: {count} images ({count/len(image_files)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüì¶ File Sizes:\")\n",
    "    print(f\"   Min: {min(file_sizes):.1f} KB | Max: {max(file_sizes):.1f} KB | Avg: {np.mean(file_sizes):.1f} KB\")\n",
    "    \n",
    "    if corrupted_files:\n",
    "        print(f\"\\n‚ö† Corrupted/Problematic Images: {len(corrupted_files)}\")\n",
    "        for fname, error in corrupted_files[:5]:\n",
    "            print(f\"   - {fname}: {error}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úì All images loaded successfully!\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREPROCESSING RECOMMENDATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    needs_resize = len(unique_dims) > 1\n",
    "    needs_normalization = True\n",
    "    needs_grayscale_conversion = 'RGB' in modes or 'RGBA' in modes\n",
    "    \n",
    "    print(\"\\nüîß Required preprocessing steps:\")\n",
    "    \n",
    "    step = 1\n",
    "    if needs_resize:\n",
    "        print(f\"\\n{step}. RESIZE IMAGES ‚ö†Ô∏è\")\n",
    "        print(f\"   Issue: {len(unique_dims)} different image sizes\")\n",
    "        print(f\"   Action: Resize all images to consistent dimensions\")\n",
    "        print(f\"   Suggested size: {max(set(widths), key=widths.count)}x{max(set(heights), key=heights.count)} (most common)\")\n",
    "        step += 1\n",
    "    else:\n",
    "        print(f\"\\n{step}. RESIZE IMAGES ‚úì\")\n",
    "        print(f\"   All images already have consistent size: {widths[0]}x{heights[0]}\")\n",
    "        step += 1\n",
    "    \n",
    "    print(f\"\\n{step}. NORMALIZATION\")\n",
    "    print(f\"   Action: Normalize pixel values to [0, 1] or [-1, 1]\")\n",
    "    print(f\"   Current: Pixel values likely in [0, 255]\")\n",
    "    step += 1\n",
    "    \n",
    "    if needs_grayscale_conversion:\n",
    "        print(f\"\\n{step}. COLOR MODE CONVERSION (Optional)\")\n",
    "        print(f\"   Current modes: {', '.join(mode_counter.keys())}\")\n",
    "        print(f\"   Consider: Converting to grayscale if color not needed\")\n",
    "        print(f\"   Benefits: Reduces model complexity, faster training\")\n",
    "        step += 1\n",
    "    \n",
    "    print(f\"\\n{step}. DATA AUGMENTATION (Recommended)\")\n",
    "    print(f\"   Techniques to consider:\")\n",
    "    print(f\"   - Random rotation (¬±5-10¬∞)\")\n",
    "    print(f\"   - Random brightness/contrast adjustment\")\n",
    "    print(f\"   - Random scaling (90-110%)\")\n",
    "    print(f\"   - Elastic distortions (for text/OCR tasks)\")\n",
    "    print(f\"   Benefits: Improves model generalization\")\n",
    "    step += 1\n",
    "    \n",
    "    print(f\"\\n{step}. VERIFY IMAGE-TEXT PAIRS\")\n",
    "    print(f\"   Action: Ensure each image has corresponding text file\")\n",
    "    print(f\"   Images: {len(image_files)}\")\n",
    "    \n",
    "    # Check for matching text files\n",
    "    txt_files = glob.glob(os.path.join(data_dir, '*.txt'))\n",
    "    print(f\"   Text files: {len(txt_files)}\")\n",
    "    \n",
    "    if len(image_files) != len(txt_files):\n",
    "        print(f\"   ‚ö†Ô∏è MISMATCH: {abs(len(image_files) - len(txt_files))} files difference\")\n",
    "    else:\n",
    "        print(f\"   ‚úì Same number of images and text files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892ffdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract basenames (without extensions)\n",
    "image_basenames = {Path(img).stem: img for img in image_files}\n",
    "txt_basenames = {Path(txt).stem: txt for txt in txt_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7552d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∑ Images WITHOUT corresponding text: 8\n",
      "   - X51005433492(1)\n",
      "   - X51005442384(1)\n",
      "   - X51005605333(1)\n",
      "   - X51005676539(1)\n",
      "   - X51005685355(2)\n",
      "   - X51005685357(2)\n",
      "   - X51007339118(1)\n",
      "   - X51007339647(1)\n",
      "\n",
      "üìù Text files WITHOUT corresponding images: 131\n",
      "   - X51005705804(1).txt\n",
      "   - X51005719917(2).txt\n",
      "   - X51005722668(1).txt\n",
      "   - X51006332575(2).txt\n",
      "   - X51006556838(1).txt\n",
      "   - X51006557202(1).txt\n",
      "   - X51006620186(1).txt\n",
      "   - X51007225417(2).txt\n",
      "   - X51007339166(1).txt\n",
      "   - X51007339639(1).txt\n",
      "   ... and 121 more\n"
     ]
    }
   ],
   "source": [
    "# Find images without text\n",
    "images_without_text = set(image_basenames.keys()) - set(txt_basenames.keys())\n",
    "print(f\"\\nüì∑ Images WITHOUT corresponding text: {len(images_without_text)}\")\n",
    "if images_without_text:\n",
    "    for basename in sorted(list(images_without_text)[:10]):\n",
    "        print(f\"   - {basename}\")\n",
    "    if len(images_without_text) > 10:\n",
    "        print(f\"   ... and {len(images_without_text) - 10} more\")\n",
    "\n",
    "# Find text without images\n",
    "text_without_images = set(txt_basenames.keys()) - set(image_basenames.keys())\n",
    "print(f\"\\nüìù Text files WITHOUT corresponding images: {len(text_without_images)}\")\n",
    "if text_without_images:\n",
    "    for basename in sorted(list(text_without_images)[:10]):\n",
    "        print(f\"   - {basename}.txt\")\n",
    "    if len(text_without_images) > 10:\n",
    "        print(f\"   ... and {len(text_without_images) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1abcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Matching pairs: 704\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è 8 images have no labels\n",
      "   Options:\n",
      "   1. Remove these images (can't train without labels)\n",
      "   2. Manually create text files for them\n",
      "   3. Move to 'unlabeled' folder for later processing\n",
      "\n",
      "‚ö†Ô∏è 131 text files have no images\n",
      "   Options:\n",
      "   1. Remove orphaned text files (most common)\n",
      "   2. Check if images exist with different extensions\n",
      "   3. Move to 'orphaned_files' folder\n"
     ]
    }
   ],
   "source": [
    "# Find matching pairs\n",
    "matching_pairs = set(image_basenames.keys()) & set(txt_basenames.keys())\n",
    "print(f\"\\n‚úì Matching pairs: {len(matching_pairs)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if images_without_text:\n",
    "    print(f\"\\n‚ö†Ô∏è {len(images_without_text)} images have no labels\")\n",
    "    print(\"   Options:\")\n",
    "    print(\"   1. Remove these images (can't train without labels)\")\n",
    "    print(\"   2. Manually create text files for them\")\n",
    "    print(\"   3. Move to 'unlabeled' folder for later processing\")\n",
    "\n",
    "if text_without_images:\n",
    "    print(f\"\\n‚ö†Ô∏è {len(text_without_images)} text files have no images\")\n",
    "    print(\"   Options:\")\n",
    "    print(\"   1. Remove orphaned text files (most common)\")\n",
    "    print(\"   2. Check if images exist with different extensions\")\n",
    "    print(\"   3. Move to 'orphaned_files' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e0fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
